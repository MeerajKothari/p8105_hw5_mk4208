---
title: "p8105_hw5_mk4208"
author: "Meeraj Kothari"
date: "11/6/2019"
output: github_document
---

# Loading Libraries

```{r message=FALSE}
library(tidyverse)
library(viridis)
library(devtools)
library(patchwork)
```

# Problem 1

The code chunk below loads the `iris` dataset from the `tidyverse` package and introduces some missing values in each column. The purpose of this problem is to fill in those missing values.

```{r message=FALSE}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

The following function that a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector.

```{r message=FALSE}
fill_missing = function(x) {
  if (is.numeric(x)) {
    replace_na(x, mean(x, na.rm = TRUE))
  } else if (is.character(x)) {
    replace_na(x, "virginica")
  }
}
```

The following code chunk applies the `fill_missing` function to the columns of `iris_with_missing` using a `map` statment. 

```{r message=FALSE}
iris_filled = map_df(iris_with_missing, fill_missing)
```

# Problem 2 

The following code chunk creates a dataframe containing all the file names within the zip folder using the `list.files` function.

```{r message=FALSE}
files = list.files("./data/", pattern = ".csv", full.names = TRUE) 
```

The following code chunk iterates over file names and reads in data for each subject using `purrr::map`, saves the result as a new variable in the dataframe and tidies the result by manipulating files names to include control arm and subject ID

```{r message=FALSE}
files_df = files %>% 
  map_df(read_csv) %>% 
  mutate(filename = tools::file_path_sans_ext(basename(files))) %>%
  separate(filename, into = c("arm", "id"), convert = TRUE) %>% 
  mutate(id = row_number()) %>%
  select(id, arm, everything()) %>%
  pivot_longer(week_1:week_8,
    names_to = "week",
    values_to = "value",
    names_prefix = "week_"
  ) %>% 
  mutate(arm = recode(arm, "con" = "Control", "exp" = "Experimental"))
```

The following code chunk maes a spaghetti plot showing observations on each subject over time. 

```{r}
files_df %>% 
  ggplot(aes(x = week, y = value, color = arm, group = id)) +
  geom_line() + 
  theme_minimal() + 
  xlab("Week") +
  ylab("Observations") +
  ggtitle("Observations on each subject over time") +
  theme(legend.position = "bottom") 
```

Based on the above create plot, we can see that the observations for the experimental arm increase over time on average compared to the observations for the control arm. 

# Problem 3 

The following code chunk writes a function `sim_regression` with the following design elements: 

* Fixed n = 30 
* Fixed xi1 draws from a standard Normal distribution 
* Fixed β0 = 2
* Fixed σ2 = 50

The function takes the argument `beta1`. 

* By default, the function sets β1 = 0 and generates a dataset from the model y = β0 + β1x + ϵ with ϵ ∼ N[0,σ2].

Additionally, it saves the β1 estimate and the p-value arising from a test of H: β1 = 0 using α = 0.05.

```{r}
set.seed(10)

sim_regression = function(beta1 = 0) {
  
  sim_data = tibble(
    x = rnorm(30, mean = 0, sd = 1),
    y = 2 + beta1 * x + rnorm(30, 0, sd = 50^(1/2))
      )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta1_hat = broom::tidy(ls_fit)[2, 2] %>% as.numeric(),
    p_value = broom::tidy(ls_fit)[2, 5] %>% as.numeric()
  )

}
```

The following code chunk generates 10000 datasets using the `sim_regression` function for β1 = {0, 1, 2, 3, 4, 5, 6}.

```{r}
sim_results = tibble(beta_1 = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(output_lists = map(.x = beta_1, ~rerun(10000, sim_regression(beta1 = .x))),
         estimate_dfs = map(output_lists, bind_rows)) %>%
  select(-output_lists) %>%
  unnest(estimate_dfs)
```

The following plot shows the proportion of times the null was rejected on the y-axis and the true value of β1 on the x-axis. 

The association between the two show us that as the effect size increases, the power also increases, when the sample size and alpha remain constant. 

```{r}
sim_results %>% 
  group_by(beta_1) %>%
  count(reject = p_value < 0.05) %>% 
  mutate(percent = n/sum(n)*100) %>% 
  filter(reject == TRUE) %>%
  ggplot(aes(x = beta_1, y = percent)) +
  geom_point() + 
  geom_line() + 
  xlab("True value of β1") +
  ylab("Proportion of times the null was rejected") +
  theme_minimal()
```

The following plots shows the average estimate of β1 on the y-axis and the true value of β1 on the x-axis. The second plot shows the average estimate of β1 **only in samples for which the null was rejected** on the y-axis and the true value of β1 on the x-axis. 

Based on this, we can see that the average estimate of β1 across the tests for which the null is rejected is not equal to the true value of β1. The β1 estimate is higher for true β1 values that are smaller and the difference between the β1 estimate and the true β1 value decreases as the true β1 values increase. This is because for the same n and alpha value, as the effect size increases the power also increases hence we can see that for β1 = 6, the difference between the β1 estimate and the true value is relatively small compared to smaller effect sizes. 
 
```{r}
p1 = sim_results %>% 
  group_by(beta_1) %>%
  summarise(mean = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta_1, y = mean)) + 
  geom_point() + 
  geom_line() + 
  xlab("True value of β1") + 
  ylab("Average estimate of β1") +
  theme_minimal()

p2 = sim_results %>% 
  filter(p_value < 0.05) %>% 
  group_by(beta_1) %>%
  summarise(mean = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta_1, y = mean)) + 
  geom_point() +
  geom_line() +
  xlab("True value of β1") + 
  ylab("Average estimate of β1\nin samples for which null was rejected") + 
  theme_minimal()

p1 + p2
```

