---
title: "p8105_hw5_mk4208"
author: "Meeraj Kothari"
date: "11/6/2019"
output: github_document
---

# Loading Libraries

```{r message=FALSE}
library(tidyverse)
library(viridis)
library(devtools)
library(patchwork)
```

# Problem 1

The code chunk below loads the `iris` dataset from the `tidyverse` package and introduces some missing values in each column. The purpose of this problem is to fill in those missing values.

```{r message=FALSE}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

The following function that a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector.

```{r message=FALSE}
fill_missing = function(x) {
  if (is.numeric(x)) {
    replace_na(x, mean(x, na.rm = TRUE))
  } else if (is.character(x)) {
    replace_na(x, "virginica")
  }
}
```

The following code chunk applies the `fill_missing` function to the columns of `iris_with_missing` using a `map` statment. 

```{r message=FALSE}
iris_filled = map_df(iris_with_missing, fill_missing)
```

# Problem 2 

The following code chunk creates a dataframe containing all the file names within the zip folder using the `list.files` function.

```{r message=FALSE}
files = list.files("./data/", pattern = ".csv", full.names = TRUE) 
```

The following code chunk iterates over file names and reads in data for each subject using `purrr::map`, saves the result as a new variable in the dataframe and tidies the result by manipulating files names to include control arm and subject ID

```{r message=FALSE}
files_df = files %>% 
  map_df(read_csv) %>% 
  mutate(filename = tools::file_path_sans_ext(basename(files))) %>%
  separate(filename, into = c("arm", "id"), convert = TRUE) %>% 
  mutate(id = row_number()) %>%
  select(id, arm, everything()) %>%
  pivot_longer(week_1:week_8,
    names_to = "week",
    values_to = "value",
    names_prefix = "week_"
  ) %>% 
  mutate(arm = recode(arm, "con" = "Control", "exp" = "Experimental"))
```

The following code chunk maes a spaghetti plot showing observations on each subject over time. 

```{r}
files_df %>% 
  ggplot(aes(x = week, y = value, color = arm, group = id)) +
  geom_line() + 
  theme_minimal() + 
  xlab("Week") +
  ylab("Observations") +
  ggtitle("Observations on each subject over time") +
  theme(legend.position = "bottom") 
```

Based on the above create plot, we can see that the observations for the experimental arm increase over time on average compared to the observations for the control arm. 

# Problem 3 

The following code chunk writes a function `sim_regression` with the following design elements: 

* Fixed $n$ = 30 
* Fixed $x_{i1}$ draws from a standard Normal distribution 
* Fixed $\beta_0$ = 2
* Fixed $\sigma^2$ = 50

The function takes the argument `beta1`. 

* By default, the function sets $\beta_1$ = 0 and generates a dataset from the model $y_i = \beta_0 + \beta_1x_{i1} + \epsilon_i$ with $\epsilon_i \sim N[0, \sigma^2]$. 

Additionally, it saves the $\hat\beta_1$ and the p-value arising from a test of $H: \beta_1 = 0$ using $\alpha = 0.05$.

```{r}
set.seed(10)

sim_regression = function(beta1 = 0) {
  
  sim_data = tibble(
    x = rnorm(30, mean = 0, sd = 1),
    y = 2 + beta1 * x + rnorm(30, 0, sd = 50^(1/2))
      )
  
  ls_fit = lm(y ~ x, data = sim_data)
  
  tibble(
    beta1_hat = broom::tidy(ls_fit)[2, 2] %>% as.numeric(),
    p_value = broom::tidy(ls_fit)[2, 5] %>% as.numeric()
  )

}
```

The following code chunk generates 10000 datasets using the `sim_regression` function for $\beta_1 = \{0, 1, 2, 3, 4, 5, 6\}$.

```{r}
sim_results = tibble(beta_1 = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(output_lists = map(.x = beta_1, ~rerun(10, sim_regression(beta1 = .x))),
         estimate_dfs = map(output_lists, bind_rows)) %>%
  select(-output_lists) %>%
  unnest(estimate_dfs)
```

The following plot shows the proportion of times the null was rejected on the y-axis and the true value of beta 1 on the x-axis. 

The association between the two show us that as the effect size increases, the power also increases, when the sample size and alpha remain constant. 

```{r}
sim_results %>% 
  group_by(beta_1) %>%
  count(reject = p_value < 0.05) %>% 
  mutate(percent = n/sum(n)*100) %>% 
  filter(reject == TRUE) %>%
  ggplot(aes(x = beta_1, y = percent)) +
  geom_point() + 
  geom_line() + 
  xlab("True value of Beta 1") +
  ylab("Proportion of times the null was rejected") +
  theme_minimal()
```

The following plots shows the average estimate of $\hat\beta_1$ on the y-axis and the true value of $\beta_1$ on the x-axis. The second plot shows the average estimate of $\hat\beta_1$ **only in samples for which the null was rejected** on the y-axis and the true value of $\beta_1$ on the x-axis. 

Based on this, we can see that the sample average of $\hat\beta_1$ across the tests for which the null is rejected is not equal to the true value of $\beta_1$. This is because as the effect size increases, power also increase. Hence, we can see that the sample beta deviates from the true beta among the samples for which the null was rejected.  
 
```{r}
p1 = sim_results %>% 
  group_by(beta_1) %>%
  summarise(mean = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta_1, y = mean)) + 
  geom_point() + 
  geom_line() + 
  xlab("True value of Beta 1") + 
  ylab("Average estimate of Beta1 hat") +
  theme_minimal()

p2 = sim_results %>% 
  filter(p_value < 0.05) %>% 
  group_by(beta_1) %>%
  summarise(mean = mean(beta1_hat)) %>% 
  ggplot(aes(x = beta_1, y = mean)) + 
  geom_point() +
  geom_line() +
  xlab("True value of Beta 1") + 
  ylab("Average estimate of Beta1 hat\nin samples for which null was rejected") + 
  theme_minimal()

p1 + p2
```

